{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf3d8bd",
   "metadata": {},
   "source": [
    "## CAS Deep Learning - Computer Vision mit Deep Learning (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023f259e-6eb2-44ca-97eb-583122c70572",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5343a8dc84bf3bc37afad76813040e73",
     "grade": false,
     "grade_id": "load",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "try:\n",
    "    import jupyter_black\n",
    "\n",
    "    jupyter_black.load()\n",
    "except:\n",
    "    print(\"black not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e420152",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10ec65559c68d0093812a9c2494e9aca",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Machine Learning Recap\n",
    "\n",
    "## Lernziele\n",
    "\n",
    "- Machine Learning Refresher zu Data-Preprocessing, Modell-Selektion und Evaluierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8227f2c8",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Im Folgenden installieren und laden wir die benötigten Python packages. Danach setzten wir die Pfade für den Zugriff auf Daten und spezifizieren einen Output-Folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c3b80",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d13eb35a868ed8cc7eac5b0282f620b",
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f067591",
   "metadata": {},
   "source": [
    "Falls Sie mit Google Colab arbeiten, wird hier Google-Drive gemounted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f85331",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"In colab: {IN_COLAB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae055ee-2a50-49c0-874d-cf2404eb0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c6a419-4d4c-416a-9336-b021c3607bd5",
   "metadata": {},
   "source": [
    "Modifizieren Sie die folgenden Pfade bei Bedarf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c3f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    DATA_PATH = Path(\"/content/drive/MyDrive/cas-dl-module-compvis-part1\")\n",
    "else:\n",
    "    DATA_PATH = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b036c41-8043-4798-8b73-586833140e4f",
   "metadata": {},
   "source": [
    "Install packages not in base Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752c859-9bb7-4b8d-b868-54911ff34072",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    os.system(\"pip install torchshow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de395f",
   "metadata": {},
   "source": [
    "## Machine Learning Recap\n",
    "\n",
    "In diesem Teil geht es darum wieder mit _Machine Learning_ vertraut zu werden. Wir werden ein einfaches Modell trainieren und dessen Performance evaluieren. Es geht noch nicht darum die einzelnen _PyTorch_ Befehle zu kennen, dazu kommen wir später.\n",
    "\n",
    "Im Wesentlichen besteht Machine Learning aus den folgenden Schritten.\n",
    "\n",
    "- Daten: Wie sollen Features / Messwerte einen Datenpunkt beschreiben? Wie muss ein Datensatz prozessiert werden?\n",
    "- Modell: Wie soll eine Fragestellung als Modell repräsentiert werden?\n",
    "- Optimisierung: Wie finde ich für ein gegebenes Modell die optimalen Modellparameter?\n",
    "- Evaluierung: Wie soll ein Modell gemessen werden? Wie soll zwischen verschiedenen Modellen das beste ausgewählt werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3719f84-bd5d-4ad1-9e45-6173dab64f13",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Nun importieren wir die nötigen Packages für diese Übung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66fa31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage\n",
    "import torch\n",
    "import torchshow as ts\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954c05bc",
   "metadata": {},
   "source": [
    "### Ziel\n",
    "\n",
    "Im Folgenden ist es unser Ziel ein Klassifikations-Modell zu trainieren mit dem man Bilder klassifizieren kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0f540",
   "metadata": {},
   "source": [
    "### Daten\n",
    "\n",
    "Um ein Modell zu trainieren brauchen wir einen Datensatz. Wir verwenden dazu den `CIFAR10` Datensatz, der praktischerweise im `torchvision` Package enthalten ist.\n",
    "\n",
    "Der Datensatz wird direkt in `DATA_PATH` abgelegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc05799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms that are applied to the data (conversion to a tensor)\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Download & Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=DATA_PATH, train=True, download=True, transform=transform\n",
    ")\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=DATA_PATH, train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# the classes of the dataset\n",
    "classes = trainset.classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3dd0af",
   "metadata": {},
   "source": [
    "Nun geht es darum die Daten zu visualisieren. Wir schauen uns die 16 ersten Bilder an. Wir verwenden dazu `torch.utils.data` Funktionalitäten und `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b832ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(\n",
    "    iter(torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=False))\n",
    ")\n",
    "\n",
    "\n",
    "def plot_square_collage_with_captions(\n",
    "    images: list[torch.Tensor], captions: list[str], caption_width: int = 30\n",
    "):\n",
    "    \"\"\"Plot Square collage with captions.\"\"\"\n",
    "    import math\n",
    "    from textwrap import wrap\n",
    "\n",
    "    num_images = len(images)\n",
    "    side_length = math.ceil(math.sqrt(num_images))\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(num_images):\n",
    "        ax = plt.subplot(side_length, side_length, i + 1)\n",
    "        caption = captions[i]\n",
    "        caption = \"\\n\".join(wrap(caption, caption_width))\n",
    "        plt.title(caption)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "\n",
    "images_list = [x.squeeze(0).permute(1, 2, 0) for x in torch.split(images, 1)]\n",
    "\n",
    "plot_square_collage_with_captions(images_list, captions=[classes[i] for i in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b8e9d6",
   "metadata": {},
   "source": [
    "Schauen Sie sich die Labels an: Sind diese korrekt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef14bffd",
   "metadata": {},
   "source": [
    "Mit dem folgenden Befehl sehen wir, dass die Bilder eine Auflösung von 32x32 Pixeln haben.\n",
    "\n",
    "(16 Bilder, 3 Farb-Channels, 32 Höhe, 32 Breite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe9add",
   "metadata": {},
   "source": [
    "Eine noch schnellere Möglichkeit Bilder anzuschauen gibt es mit dem Package `torchshow` (jedoch ohne die Labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.show(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5942c3aa-9a13-4371-9de7-99e6a58547aa",
   "metadata": {},
   "source": [
    "Auch mit `torchvision` kann man die Bilder relativ einfach anschauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a98b31b-4c46-4529-990b-1f2bd49cedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "\n",
    "image_grid = make_grid(images)\n",
    "image_grid = F.to_pil_image(image_grid)\n",
    "\n",
    "_ = plt.imshow(image_grid)\n",
    "_ = plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872066ce",
   "metadata": {},
   "source": [
    "### Modell & Optimisierung\n",
    "\n",
    "Nun geht es darum Modelle zu definieren, mit denen man lernen kann Bilder zu klassifizieren.\n",
    "\n",
    "Als erstes implementieren wir die Modelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidClassifier:\n",
    "\n",
    "    def __init__(self, num_classes, shape):\n",
    "        self.num_classes = num_classes\n",
    "        self.shape = shape\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        class_sum = torch.zeros((self.num_classes,) + self.shape)\n",
    "        class_counts = torch.zeros(self.num_classes)\n",
    "        for i in range(self.num_classes):\n",
    "            class_sum[i] += torch.sum(X[y == i], dim=0)\n",
    "            class_counts[i] += torch.sum(y == i)\n",
    "        centroids = class_sum / class_counts.view(self.num_classes, 1, 1, 1)\n",
    "        self.centroids = centroids\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        centroids = self.centroids.view(self.num_classes, -1)\n",
    "        X = X.view(X.size(0), -1)\n",
    "        # Compute distances to centroids\n",
    "        dists = torch.cdist(X, centroids)\n",
    "        return torch.argmin(dists, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ab0645",
   "metadata": {},
   "source": [
    "**FRAGE**: Was macht dieses Modell? Interpretieren Sie die Klasse `CentroidClassifier`\n",
    "\n",
    "**FRAGE**: Welche Modell-Parameter werden gelernt / optimisiert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ecefa1-a61e-4828-9ebc-a74c910980b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClosestNeighborClassifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Reshape input images\n",
    "        X_flat = X.view(X.shape[0], -1)\n",
    "        X_train_flattened = self.X_train.view(self.X_train.shape[0], -1)\n",
    "        \n",
    "        # Compute distances to all training samples\n",
    "        dists = torch.cdist(X_flat, X_train_flattened)\n",
    "        \n",
    "        # Get the indices of the minimum distances\n",
    "        indices_of_min_dists = torch.argmin(dists, dim=1)\n",
    "        \n",
    "        # Return the labels of the closest training samples\n",
    "        return self.y_train[indices_of_min_dists]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b276af-6fd2-4d36-8781-bb11f071d1ac",
   "metadata": {},
   "source": [
    "**FRAGE**: Was macht dieses Modell? Interpretieren Sie die Klasse `ClosestNeighborClassifier` \n",
    "\n",
    "**FRAGE**: Welche Modell-Parameter werden gelernt / optimisiert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709fd07-4389-4d1e-94b3-c1be7680292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionClassifier:\n",
    "    def __init__(self):\n",
    "        # Logistic Regression model\n",
    "        self.model = LogisticRegression()\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = X.view(X.shape[0], -1)\n",
    "        X = X / 255.0\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.view(X.shape[0], -1)\n",
    "        X = X / 255.0\n",
    "        y = self.model.predict(X)\n",
    "        return torch.from_numpy(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d065957-2ffe-4c4f-aacb-03d2547d0cc5",
   "metadata": {},
   "source": [
    "**FRAGE**: Was macht dieses Modell? Interpretieren Sie die Klasse `LogisticRegressionClassifier` \n",
    "\n",
    "**FRAGE**: Welche Modell-Parameter werden gelernt / optimisiert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3535c0-c64d-4b97-8eca-152d2bd7a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "class HOGClassifier:\n",
    "\n",
    "    def __init__(self, k):\n",
    "        # Initialize the class with a given number k for k-nearest neighbors\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        features = []\n",
    "        # Loop over each image in X to compute its HOG feature\n",
    "        for i in tqdm(range(0, X.shape[0])):\n",
    "            fd = self._hog(X[i])\n",
    "            features.append(torch.tensor(fd))\n",
    "            \n",
    "        self.features_train = torch.stack(features)\n",
    "        self.y_train = y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        features = []\n",
    "        # Loop over each image in X to compute its HOG feature\n",
    "        for i in range(0, X.shape[0]):\n",
    "            fd = self._hog(X[i]) \n",
    "            features.append(torch.tensor(fd))\n",
    "\n",
    "        features_test = torch.stack(features)\n",
    "        \n",
    "        # Compute L2 distances between each test feature and all training features\n",
    "        dists = torch.cdist(features_test, self.features_train)\n",
    "        \n",
    "        # Obtain indices of the k smallest distances for each test feature\n",
    "        _, indices = dists.topk(self.k, dim=1, largest=False)\n",
    "        \n",
    "        y_pred = []\n",
    "        \n",
    "        # For each set of k nearest neighbors, determine the most common label\n",
    "        for index_set in indices:\n",
    "            nearest_labels = self.y_train[index_set]\n",
    "            most_common = Counter(nearest_labels.numpy()).most_common(1)\n",
    "            y_pred.append(most_common[0][0])\n",
    "        \n",
    "        # Convert list of predicted labels to tensor and return\n",
    "        return torch.tensor(y_pred)\n",
    "\n",
    "    def _hog(self, X):\n",
    "        # Internal helper method to compute HOG feature for a given image X\n",
    "        image = transforms.functional.to_pil_image(X)\n",
    "        fd = hog(image,\n",
    "                 orientations=8,\n",
    "                 pixels_per_cell=(16, 16),\n",
    "                 cells_per_block=(1, 1),\n",
    "                 visualize=False,\n",
    "                 channel_axis=-1,\n",
    "                 feature_vector=True)\n",
    "        return fd\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7f0e48-a701-41e9-bfbf-85c102b68834",
   "metadata": {},
   "source": [
    "**FRAGE**: Was macht dieses Modell? Interpretieren Sie die Klasse `HOGClassifier`\n",
    "\n",
    "**FRAGE**: Welche Modell-Parameter werden gelernt / optimisiert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4394930-2171-44ea-af6f-189ed5d2dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class HOGClassifier2:\n",
    "    def __init__(self):\n",
    "        # Logistic Regression model\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        features = []\n",
    "        # Loop over each image in X to compute its HOG feature\n",
    "        for i in tqdm(range(0, X.shape[0])):\n",
    "            fd = self._hog(X[i])\n",
    "            features.append(fd)\n",
    "        \n",
    "        # Train the logistic regression model\n",
    "        features = np.stack(features)\n",
    "        features = self.scaler.fit_transform(features)\n",
    "        self.model.fit(features, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        features = []\n",
    "        # Loop over each image in X to compute its HOG feature\n",
    "        for i in range(0, X.shape[0]):\n",
    "            fd = self._hog(X[i]) \n",
    "            features.append(fd)\n",
    "        features = np.stack(features)\n",
    "        features = self.scaler.transform(features)\n",
    "        \n",
    "        # Use the logistic regression model to make predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        return torch.from_numpy(y_pred)\n",
    "\n",
    "    def _hog(self, X):\n",
    "        # Internal helper method to compute HOG feature for a given image X\n",
    "        image = transforms.functional.to_pil_image(X)\n",
    "        fd = hog(image,\n",
    "                 orientations=8,\n",
    "                 pixels_per_cell=(16, 16),\n",
    "                 cells_per_block=(1, 1),\n",
    "                 visualize=False,\n",
    "                 channel_axis=-1,\n",
    "                 feature_vector=True)\n",
    "        return fd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8448fc9-fbc7-44f9-a399-178af67d381c",
   "metadata": {},
   "source": [
    "**FRAGE**: Was macht dieses Modell? Interpretieren Sie die Klasse `HOGClassifier2`\n",
    "\n",
    "**FRAGE**: Welche Modell-Parameter werden gelernt / optimisiert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d820576-9323-4fde-bdd0-aa64774c0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "class ColorHistogramClassifier:\n",
    "\n",
    "    def __init__(self, num_bins=256):\n",
    "        # Initialize the logistic regression model\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.num_bins = num_bins\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        features = []\n",
    "        # Extract color histogram features from the images\n",
    "        for i in tqdm(range(0, X.shape[0])):\n",
    "            fd = self._color_histogram(X[i])\n",
    "            features.append(fd)\n",
    "        \n",
    "        # Train the logistic regression model\n",
    "        features = np.stack(features)\n",
    "        features = self.scaler.fit_transform(features)\n",
    "        self.model.fit(features, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        features = []\n",
    "        # Loop over each image in X to compute its HOG feature\n",
    "        for i in range(0, X.shape[0]):\n",
    "            fd = self._color_histogram(X[i]) \n",
    "            features.append(fd)\n",
    "        features = np.stack(features)\n",
    "        features = self.scaler.transform(features)\n",
    "        \n",
    "        # Use the logistic regression model to make predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        return torch.from_numpy(y_pred)\n",
    "        \n",
    "    def _color_histogram(self, image):\n",
    "        # Compute the color histogram for each color channel\n",
    "        histograms = [np.histogram(image[i, :, :], bins=self.num_bins, range=(0, 256))[0]\n",
    "                      for i in range(image.shape[0])]\n",
    "        \n",
    "        # Concatenate histograms into a single feature\n",
    "        hist_features = np.concatenate(histograms)\n",
    "        \n",
    "        # Normalize the histogram so that images with different scales contribute equally\n",
    "        hist_features = hist_features / np.linalg.norm(hist_features)\n",
    "        return hist_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50321b7-b6ae-405b-88a0-b55efeb25d66",
   "metadata": {},
   "source": [
    "**FRAGE**: Was macht dieses Modell? Interpretieren Sie die Klasse `ColorHistogramClassifier`\n",
    "\n",
    "**FRAGE**: Welche Modell-Parameter werden gelernt / optimisiert?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a75a96-c558-4e45-9942-ab991718d2f4",
   "metadata": {},
   "source": [
    "**FRAGE**: Für welches Modell erwarten Sie die höhere Genauigkeit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd15a2-5cc9-49db-9fe7-916e160c351c",
   "metadata": {},
   "source": [
    "### Evaluierung  und Modell-Selektion\n",
    "\n",
    "In dieser Sektion geht es darum zu definieren, wie ein Modell gemessen wird (Metrik). Eine gängige Metrik für Klassifikationsprobleme ist die `Accuracy`. Diese beschreibt den Anteil der korrekten Klassifikationen und ist somit im Range $[0, 1]$.\n",
    "\n",
    "Ausserdem geht es darum mehrere Modelle zu vergleichen und das Beste zu identifizieren. \n",
    "\n",
    "Dazu teilen wir die Trainings-Daten in einen Train- und einen Validation-Split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc9bf5-7123-4e38-a9fe-cfcd4ac97386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define the lengths\n",
    "train_length = int(0.8 * len(trainset)) # 80% of the dataset for training\n",
    "val_length = len(trainset) - train_length # remaining for validation\n",
    "\n",
    "# Split the dataset\n",
    "rng = torch.Generator().manual_seed(123)\n",
    "train_split, validation_split = random_split(trainset, [train_length, val_length], generator=rng)\n",
    "\n",
    "print(f\"train_split size: {len(train_split)}\")\n",
    "print(f\"validation_split size: {len(validation_split)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed76921-c4af-4806-9c9a-94c8c134b9b8",
   "metadata": {},
   "source": [
    "**FRAGE**: Warum brauchen wir einen Train-Test-Validation Split? Beziehungsweise, welches Modell wäre auf den Trainingsdaten evaluiert, wohl das beste?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca689ee-2c7d-471a-9372-4024e52be036",
   "metadata": {},
   "source": [
    "Nun laden wir die Daten in Memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae0104-e36e-4e70-8b7e-9e3e3b9d86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_split, batch_size=len(train_split), shuffle=False)\n",
    "Xtrain, ytrain = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cf06d9-6dc4-4f9b-bc23-16c620b8af6c",
   "metadata": {},
   "source": [
    "Wir definieren die Modelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e059d11-cc97-4b6f-bcca-ff2423e7aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models = {\n",
    "    'centroid': CentroidClassifier(num_classes=10, shape=(3, 32, 32)),\n",
    "    'nearest_neighbour': ClosestNeighborClassifier(),\n",
    "    'logistic_regression': LogisticRegressionClassifier(),\n",
    "    'hog_classifier': HOGClassifier(k=20),\n",
    "    'hog_classifier2': HOGClassifier2(),\n",
    "    'color_hist': ColorHistogramClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7303e26a-cb9b-46ac-9957-a492f51ee945",
   "metadata": {},
   "source": [
    "Nun trainieren / fitten wir die Modelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2a897-3e86-40a4-a63b-712f8a3f59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"Fitting: {name}\")\n",
    "    model = model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f7ff6-4e4e-4de1-9ae9-8127c7dce421",
   "metadata": {},
   "source": [
    "**FRAGE:** Welches Modell hat am längest gebraucht und warum?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e2d5f7-3b62-44c4-9eab-573d3c370e84",
   "metadata": {},
   "source": [
    "Nun laden wir die Validierungsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a191be2f-a671-4098-8cbd-24c6cb17d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valloader = torch.utils.data.DataLoader(validation_split, batch_size=1024, shuffle=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a1b3c-6e57-44bc-bb17-2bbee084207a",
   "metadata": {},
   "source": [
    "Nun generieren wir Vorhersagen / Predictions für die Validierungs-Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de210b65-22dd-4390-9d3c-c1d12d499f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_all = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Predicting: {name}\")\n",
    "    predictions_batches = list()\n",
    "    for Xbatch, ybatch in tqdm(valloader, total=len(valloader)):\n",
    "        predictions_batches.append(model.predict(Xbatch))\n",
    "    predictions_all[name] = torch.concat(predictions_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb481adf-7efd-4034-811e-7440ad46e00c",
   "metadata": {},
   "source": [
    "**FRAGE:** Welches Modell hat am längest gebraucht und warum?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b6e05-68eb-4c0c-b80f-51f8dbbe029a",
   "metadata": {},
   "source": [
    "Nun berechnen wir die Accuracy für die Modelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5fba01-edee-4c6d-9661-8a8d39bff3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "yval_true = torch.tensor([y for x, y in validation_split])\n",
    "\n",
    "accs = {}\n",
    "for name, predictions in predictions_all.items():\n",
    "    acc = (predictions == yval_true).to(torch.float).mean()\n",
    "    accs[name] = acc\n",
    "    print(f\"Accuracy {name}: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2277da78",
   "metadata": {},
   "source": [
    "Will man die Performance des besten Modelles abschätzen evaluiert man es oft nochmal auf einem Testdatensatz. Dieser darf nicht in der Modell-Selektion verwendet worden sein. Dadurch erhält man eine genauere Einschätzung der Performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1024, shuffle=False)\n",
    "ytest_true = torch.tensor([y for x, y in testset])\n",
    "\n",
    "predictions_batches = list()\n",
    "\n",
    "best_model_name = max(accs, key=accs.get)\n",
    "print(f\"best model: {best_model_name}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "for Xbatch, ybatch in tqdm(testloader, total=len(testloader)):\n",
    "    predictions_batches.append(best_model.predict(Xbatch))\n",
    "predictions_all = torch.concat(predictions_batches)\n",
    "\n",
    "\n",
    "acc = (predictions_all == ytest_true).to(torch.float).mean()\n",
    "print(f\"Accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cfd310-7d34-4de4-bfda-ed95d1aa7d81",
   "metadata": {},
   "source": [
    "### (Optional) Weitere Aufgaben\n",
    "\n",
    "- Erstellen Sie ein weiteres Modell und vergleichen Sie dessen Performance.\n",
    "\n",
    "- Visualisieren Sie die `nearest neighbours` von verschiedenen Datenpunkten.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
